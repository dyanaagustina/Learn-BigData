import pandas as pds
import seaborn as sbn
import numpy as npy
import matplotlib.pyplot as plb
import statsmodels.api as sm

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report


data_heart = pds.read_csv('heart.csv')
data_heart.head()

data_heart.shape

data_heart.info()

data_heart.isnull().sum()

data_heart.describe()

x = data_heart.drop(columns='target')
y = data_heart['target']

result_log = sm.Logit(y, sm.add_constant(x)).fit()

print(result_log.summary())

data_var_sig = data_heart.drop(columns=['age', 'trestbps', 'chol', 'fbs', 'restecg', 'slope'])

data_var_sig.head()

x = data_var_sig.drop(columns='target')
y = data_var_sig['target']

result_log = sm.Logit(y, sm.add_constant(x)).fit()

print(result_log.summary())

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=0)

_scaling = StandardScaler()
x_train_scaled = _scaling.fit_transform(x_train)
x_test_scaled = _scaling.transform(x_test)

_reg = LogisticRegression()
log_reg = _reg.fit(x_train_scaled, y_train)

print(log_reg.intercept_)

pred = _reg.predict(x_test_scaled)

y_pred_prob = _reg.predict_proba(x_test_scaled)[:,1]

data_prob = pds.DataFrame(x_test)
data_prob['prob_value'] = y_pred_prob
data_prob['prob'] = pred

data_prob

print(data_prob['prob'].value_counts())

print(classification_report(y_test, pred))
